{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and Restore TensorFlow Models\n",
    "====================\n",
    "\n",
    "Training a model can take hours. But once you close your TensorFlow session, you lose all the trained weights and biases. If you were to reuse the model in the future, you would have to train it all over again!\n",
    "\n",
    "Fortunately, TensorFlow gives you the ability to save your progress using a class called tf.train.Saver. This class provides the functionality to save any tf.Variable to your file system.\n",
    "Saving Variables\n",
    "\n",
    "Let's start with a simple example of saving weights and bias Tensors. For the first example you'll just save two variables. Later examples will save all the weights in a practical model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[ 0.4694736   0.05892888  1.78839195]\n",
      " [ 0.98662198 -0.14390811  1.30576253]]\n",
      "Bias:\n",
      "[-0.04815755  1.78597128 -0.11531379]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Weights:\n",
    ">\n",
    ">    [[-0.97990924 1.03016174 0.74119264]\n",
    ">\n",
    ">    [-0.82581609 -0.07361362 -0.86653847]]\n",
    ">\n",
    "> Bias:\n",
    ">\n",
    ">    [ 1.62978125 -0.37812829 0.64723819] \n",
    "\n",
    "The Tensors weights and bias are set to random values using the tf.truncated_normal() function. The values are then saved to the save_file location, \"model.ckpt\", using the tf.train.Saver.save() function. (The \".ckpt\" extension stands for \"checkpoint\".)\n",
    "\n",
    "If you're using TensorFlow 0.11.0RC1 or newer, a file called \"model.ckpt.meta\" will also be created. This file contains the TensorFlow graph.\n",
    "\n",
    "### Loading Variables\n",
    "\n",
    "Now that the Tensor Variables are saved, let's load them back into a new model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Weight:\n",
      "[[ 0.4694736   0.05892888  1.78839195]\n",
      " [ 0.98662198 -0.14390811  1.30576253]]\n",
      "Bias:\n",
      "[-0.04815755  1.78597128 -0.11531379]\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Weights:\n",
    ">\n",
    ">    [[-0.97990924 1.03016174 0.74119264]\n",
    ">\n",
    ">    [-0.82581609 -0.07361362 -0.86653847]]\n",
    ">\n",
    ">    Bias:\n",
    ">\n",
    ">    [ 1.62978125 -0.37812829 0.64723819]\n",
    "    \n",
    "\n",
    "You'll notice you still need to create the weights and bias Tensors in Python. The tf.train.Saver.restore() function loads the saved data into weights and bias.\n",
    "\n",
    "Since tf.train.Saver.restore() sets all the TensorFlow Variables, you don't need to call tf.global_variables_initializer().\n",
    "\n",
    "### Save a Trained Model\n",
    "\n",
    "Let's see how to train a model and save its weights.\n",
    "\n",
    "First start with a model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train that model, then save the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.14659999310970306\n",
      "Epoch 10  - Validation Accuracy: 0.3361999988555908\n",
      "Epoch 20  - Validation Accuracy: 0.4641999900341034\n",
      "Epoch 30  - Validation Accuracy: 0.5447999835014343\n",
      "Epoch 40  - Validation Accuracy: 0.5952000021934509\n",
      "Epoch 50  - Validation Accuracy: 0.6284000277519226\n",
      "Epoch 60  - Validation Accuracy: 0.6600000262260437\n",
      "Epoch 70  - Validation Accuracy: 0.6815999746322632\n",
      "Epoch 80  - Validation Accuracy: 0.7038000226020813\n",
      "Epoch 90  - Validation Accuracy: 0.7193999886512756\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Epoch 0 - Validation Accuracy: 0.06859999895095825\n",
    ">\n",
    ">    Epoch 10 - Validation Accuracy: 0.20239999890327454\n",
    ">\n",
    ">    Epoch 20 - Validation Accuracy: 0.36980000138282776\n",
    ">\n",
    ">    Epoch 30 - Validation Accuracy: 0.48820000886917114\n",
    ">\n",
    ">    Epoch 40 - Validation Accuracy: 0.5601999759674072\n",
    ">\n",
    ">    Epoch 50 - Validation Accuracy: 0.6097999811172485\n",
    ">\n",
    ">    Epoch 60 - Validation Accuracy: 0.6425999999046326\n",
    ">\n",
    ">    Epoch 70 - Validation Accuracy: 0.6733999848365784\n",
    ">\n",
    ">    Epoch 80 - Validation Accuracy: 0.6916000247001648\n",
    ">\n",
    ">    Epoch 90 - Validation Accuracy: 0.7113999724388123\n",
    "\n",
    "    Trained Model Saved.\n",
    "\n",
    "### Load a Trained Model\n",
    "\n",
    "Let's load the weights and bias from memory, then check the test accuracy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
      "Test Accuracy: 0.7299000024795532\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Test Accuracy: 0.7229999899864197\n",
    "\n",
    "That's it! You now know how to save and load a trained model in TensorFlow. Let's look at loading weights and biases into modified models in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
